{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-09 03:00:42.006 | DEBUG    | __main__:<module>:28 - All modules imported\n"
     ]
    }
   ],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from vgg import *\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, TerminateOnNaN, TensorBoard\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import copy\n",
    "import sys\n",
    "from loguru import logger\n",
    "\n",
    "\n",
    "logger.debug('All modules imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-09 02:40:28.424 | DEBUG    | __main__:<module>:11 - [INFO] loading images...\n",
      "2020-02-09 02:40:49.295 | DEBUG    | __main__:<module>:38 - [INFO] data loaded complete...\n"
     ]
    }
   ],
   "source": [
    "# current working directory\n",
    "cur_dir = os.getcwd()\n",
    "\n",
    "# the data is located in this data_dir\n",
    "data_dir = os.path.join(cur_dir, 'Dataset')\n",
    "\n",
    "# the output model and the graph is saved in this 'output_dir'\n",
    "output_dir = os.path.join(cur_dir, 'Output')\n",
    "\n",
    "# initialize the data and labels\n",
    "logger.debug(\"[INFO] loading images...\")\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# grab the image paths and shuffle them\n",
    "# for reproducible results, use a constant seed for shuffling\n",
    "imagePaths = sorted(list(paths.list_images(os.path.join(data_dir, 'Data') )))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "    \n",
    "    # load the image\n",
    "    image = cv2.imread(imagePath)\n",
    "    \n",
    "    # resize it\n",
    "    image = cv2.resize(image, (32, 32))\n",
    "    \n",
    "    # append to the data list\n",
    "    data.append(image)\n",
    "\n",
    "    # extract the class label from the image path and update the labels list\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(label)\n",
    "\n",
    "\n",
    "logger.debug('[INFO] data loaded complete...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loaded = copy.deepcopy(data)\n",
    "labels_loaded = copy.deepcopy(labels)\n",
    "\n",
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data_loaded, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels_loaded)\n",
    "\n",
    "# Binarize labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "\n",
    "# Randomly split the data into test and train sets (25% test and 75% train)\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "    horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "# initialize our VGG-like Convolutional Neural Network\n",
    "model = SmallVGGNet.build(width=32, height=32, depth=3,\n",
    "    classes=len(lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tensorboard_v1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-341d0d66a832>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mINIT_LR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtensorboard_v1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistogram_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_grads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings_layer_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tensorboard_v1' is not defined"
     ]
    }
   ],
   "source": [
    "# initialize our initial learning rate, # of epochs to train for,\n",
    "# and batch size\n",
    "INIT_LR = 0.005\n",
    "EPOCHS = 50\n",
    "BS = 32\n",
    "\n",
    "# TODO: Set the filepath under which you want to save the model.\n",
    "model_checkpoint = ModelCheckpoint(filepath='VGG_epoch-{epoch:02d}_loss-{loss:.4f}_val_loss-{val_loss:.4f}.h5',\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=False,\n",
    "                                   mode='auto',\n",
    "                                   period=20)\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "tb = TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch')\n",
    "\n",
    "callbacks = [model_checkpoint, tb,terminate_on_nan]\n",
    "\n",
    "# initialize the model and optimizer\n",
    "print(\"[INFO] training network...\")\n",
    "# opt = SGD(lr=INIT_LR, momentum=0.5, decay=INIT_LR / EPOCHS)\n",
    "\n",
    "opt = Adam(lr=INIT_LR, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "# train the network\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),\n",
    "    validation_data=(testX, testY), steps_per_epoch=len(trainX) // BS,\n",
    "    epochs=EPOCHS,callbacks=callbacks)\n",
    "\n",
    "\n",
    "\n",
    "# Save the model locally for use later\n",
    "model_path = os.path.join(output_dir, 'path_to_my_VGG_model.h5')\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate the network\n",
    "logger.debug('Making predictions and evaluating the trained model.')\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),predictions.argmax(axis=1), target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "N = np.arange(0, EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(N, H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir,'smallvggnet_plot.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
