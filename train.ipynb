{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-09 03:00:42.006 | DEBUG    | __main__:<module>:28 - All modules imported\n"
     ]
    }
   ],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from vgg import *\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, TerminateOnNaN, TensorBoard\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import copy\n",
    "import sys\n",
    "from loguru import logger\n",
    "\n",
    "\n",
    "logger.debug('All modules imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-09 02:40:28.424 | DEBUG    | __main__:<module>:11 - [INFO] loading images...\n",
      "2020-02-09 02:40:49.295 | DEBUG    | __main__:<module>:38 - [INFO] data loaded complete...\n"
     ]
    }
   ],
   "source": [
    "# current working directory\n",
    "cur_dir = os.getcwd()\n",
    "\n",
    "# the data is located in this data_dir\n",
    "data_dir = os.path.join(cur_dir, 'Dataset')\n",
    "\n",
    "# the output model and the graph is saved in this 'output_dir'\n",
    "output_dir = os.path.join(cur_dir, 'Output')\n",
    "\n",
    "# initialize the data and labels\n",
    "logger.debug(\"[INFO] loading images...\")\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# grab the image paths and shuffle them\n",
    "# for reproducible results, use a constant seed for shuffling\n",
    "imagePaths = sorted(list(paths.list_images(os.path.join(data_dir, 'Data') )))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "    \n",
    "    # load the image\n",
    "    image = cv2.imread(imagePath)\n",
    "    \n",
    "    # resize it\n",
    "    image = cv2.resize(image, (32, 32))\n",
    "    \n",
    "    # append to the data list\n",
    "    data.append(image)\n",
    "\n",
    "    # extract the class label from the image path and update the labels list\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(label)\n",
    "\n",
    "\n",
    "logger.debug('[INFO] data loaded complete...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loaded = copy.deepcopy(data)\n",
    "labels_loaded = copy.deepcopy(labels)\n",
    "\n",
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data_loaded, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels_loaded)\n",
    "\n",
    "# Binarize labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "\n",
    "# Randomly split the data into test and train sets (25% test and 75% train)\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "    horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "# initialize our VGG-like Convolutional Neural Network\n",
    "model = SmallVGGNet.build(width=32, height=32, depth=3,\n",
    "    classes=len(lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/50\n",
      "118/118 [==============================] - 45s 381ms/step - loss: 1.8224 - acc: 0.4637 - val_loss: 4.6939 - val_acc: 0.3027\n",
      "Epoch 2/50\n",
      "118/118 [==============================] - 30s 250ms/step - loss: 1.1517 - acc: 0.6417 - val_loss: 1.7227 - val_acc: 0.5483\n",
      "Epoch 3/50\n",
      "118/118 [==============================] - 30s 251ms/step - loss: 0.9708 - acc: 0.7092 - val_loss: 2.7639 - val_acc: 0.4390\n",
      "Epoch 4/50\n",
      "118/118 [==============================] - 30s 258ms/step - loss: 0.7739 - acc: 0.7489 - val_loss: 0.9120 - val_acc: 0.7678\n",
      "Epoch 5/50\n",
      "118/118 [==============================] - 32s 271ms/step - loss: 0.6875 - acc: 0.7844 - val_loss: 1.0122 - val_acc: 0.6918\n",
      "Epoch 6/50\n",
      "118/118 [==============================] - 37s 315ms/step - loss: 0.6704 - acc: 0.7913 - val_loss: 0.6397 - val_acc: 0.8296\n",
      "Epoch 7/50\n",
      "118/118 [==============================] - 31s 259ms/step - loss: 0.6110 - acc: 0.8058 - val_loss: 0.7351 - val_acc: 0.7773\n",
      "Epoch 8/50\n",
      "118/118 [==============================] - 31s 262ms/step - loss: 0.5432 - acc: 0.8224 - val_loss: 0.9616 - val_acc: 0.7544\n",
      "Epoch 9/50\n",
      "118/118 [==============================] - 35s 297ms/step - loss: 0.5189 - acc: 0.8330 - val_loss: 0.4482 - val_acc: 0.8597\n",
      "Epoch 10/50\n",
      "118/118 [==============================] - 31s 262ms/step - loss: 0.5429 - acc: 0.8337 - val_loss: 0.6120 - val_acc: 0.8415\n",
      "Epoch 11/50\n",
      "118/118 [==============================] - 32s 271ms/step - loss: 0.5296 - acc: 0.8430 - val_loss: 0.5101 - val_acc: 0.8653\n",
      "Epoch 12/50\n",
      "118/118 [==============================] - 29s 248ms/step - loss: 0.4796 - acc: 0.8538 - val_loss: 0.5667 - val_acc: 0.8312\n",
      "Epoch 13/50\n",
      "118/118 [==============================] - 31s 264ms/step - loss: 0.4675 - acc: 0.8497 - val_loss: 0.6890 - val_acc: 0.8082\n",
      "Epoch 14/50\n",
      "118/118 [==============================] - 35s 296ms/step - loss: 0.4793 - acc: 0.8506 - val_loss: 1.3183 - val_acc: 0.5808\n",
      "Epoch 15/50\n",
      "118/118 [==============================] - 29s 242ms/step - loss: 0.4490 - acc: 0.8555 - val_loss: 0.3959 - val_acc: 0.8796\n",
      "Epoch 16/50\n",
      "118/118 [==============================] - 28s 239ms/step - loss: 0.4568 - acc: 0.8533 - val_loss: 0.3766 - val_acc: 0.8867\n",
      "Epoch 17/50\n",
      "118/118 [==============================] - 29s 243ms/step - loss: 0.3769 - acc: 0.8840 - val_loss: 0.3715 - val_acc: 0.8938\n",
      "Epoch 18/50\n",
      "118/118 [==============================] - 28s 240ms/step - loss: 0.4082 - acc: 0.8747 - val_loss: 0.4608 - val_acc: 0.8590\n",
      "Epoch 19/50\n",
      "118/118 [==============================] - 32s 271ms/step - loss: 0.3866 - acc: 0.8745 - val_loss: 0.3665 - val_acc: 0.9033\n",
      "Epoch 20/50\n",
      "118/118 [==============================] - 33s 277ms/step - loss: 0.4257 - acc: 0.8743 - val_loss: 0.5515 - val_acc: 0.8463\n",
      "\n",
      "Epoch 00020: val_loss improved from inf to 0.55151, saving model to VGG_epoch-20_loss-0.4181_val_loss-0.5515.h5\n",
      "Epoch 21/50\n",
      "118/118 [==============================] - 34s 285ms/step - loss: 0.3554 - acc: 0.8887 - val_loss: 0.3298 - val_acc: 0.9105\n",
      "Epoch 22/50\n",
      "118/118 [==============================] - 31s 263ms/step - loss: 0.4026 - acc: 0.8716 - val_loss: 0.4954 - val_acc: 0.8542\n",
      "Epoch 23/50\n",
      "118/118 [==============================] - 32s 271ms/step - loss: 0.3372 - acc: 0.8931 - val_loss: 0.4752 - val_acc: 0.8320\n",
      "Epoch 24/50\n",
      "118/118 [==============================] - 28s 239ms/step - loss: 0.3518 - acc: 0.8906 - val_loss: 0.4927 - val_acc: 0.8772\n",
      "Epoch 25/50\n",
      "118/118 [==============================] - 28s 234ms/step - loss: 0.3311 - acc: 0.8917 - val_loss: 0.2986 - val_acc: 0.9081\n",
      "Epoch 26/50\n",
      "118/118 [==============================] - 31s 261ms/step - loss: 0.3418 - acc: 0.8922 - val_loss: 0.3720 - val_acc: 0.8819\n",
      "Epoch 27/50\n",
      "118/118 [==============================] - 31s 260ms/step - loss: 0.3230 - acc: 0.8976 - val_loss: 0.3397 - val_acc: 0.9049\n",
      "Epoch 28/50\n",
      "118/118 [==============================] - 31s 264ms/step - loss: 0.3367 - acc: 0.8955 - val_loss: 0.2611 - val_acc: 0.9200\n",
      "Epoch 29/50\n",
      "118/118 [==============================] - 29s 248ms/step - loss: 0.3387 - acc: 0.8943 - val_loss: 0.4424 - val_acc: 0.8693\n",
      "Epoch 30/50\n",
      "118/118 [==============================] - 28s 239ms/step - loss: 0.2782 - acc: 0.9130 - val_loss: 0.3778 - val_acc: 0.8819\n",
      "Epoch 31/50\n",
      "118/118 [==============================] - 28s 235ms/step - loss: 0.3025 - acc: 0.8992 - val_loss: 0.5032 - val_acc: 0.8597\n",
      "Epoch 32/50\n",
      "118/118 [==============================] - 31s 266ms/step - loss: 0.2706 - acc: 0.9147 - val_loss: 0.3303 - val_acc: 0.9065\n",
      "Epoch 33/50\n",
      "118/118 [==============================] - 32s 272ms/step - loss: 0.2978 - acc: 0.9038 - val_loss: 0.2945 - val_acc: 0.9120\n",
      "Epoch 34/50\n",
      "118/118 [==============================] - 29s 247ms/step - loss: 0.2807 - acc: 0.9122 - val_loss: 0.3425 - val_acc: 0.8922\n",
      "Epoch 35/50\n",
      "118/118 [==============================] - 29s 245ms/step - loss: 0.2925 - acc: 0.9041 - val_loss: 0.3201 - val_acc: 0.9010\n",
      "Epoch 36/50\n",
      "118/118 [==============================] - 29s 244ms/step - loss: 0.2926 - acc: 0.9081 - val_loss: 0.4159 - val_acc: 0.8780\n",
      "Epoch 37/50\n",
      "118/118 [==============================] - 29s 245ms/step - loss: 0.2602 - acc: 0.9175 - val_loss: 0.4533 - val_acc: 0.8788\n",
      "Epoch 38/50\n",
      "118/118 [==============================] - 29s 246ms/step - loss: 0.2858 - acc: 0.9115 - val_loss: 0.3157 - val_acc: 0.9049\n",
      "Epoch 39/50\n",
      "118/118 [==============================] - 29s 245ms/step - loss: 0.2594 - acc: 0.9208 - val_loss: 0.3567 - val_acc: 0.8994\n",
      "Epoch 40/50\n",
      " 84/118 [====================>.........] - ETA: 8s - loss: 0.2649 - acc: 0.9185"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-bb4ec909cb30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),\n\u001b[1;32m     33\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     epochs=EPOCHS,callbacks=callbacks)\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# initialize our initial learning rate, # of epochs to train for,\n",
    "# and batch size\n",
    "INIT_LR = 0.005\n",
    "EPOCHS = 50\n",
    "BS = 32\n",
    "\n",
    "# TODO: Set the filepath under which you want to save the model.\n",
    "model_checkpoint = ModelCheckpoint(filepath='VGG_epoch-{epoch:02d}_loss-{loss:.4f}_val_loss-{val_loss:.4f}.h5',\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=False,\n",
    "                                   mode='auto',\n",
    "                                   period=20)\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "tb = TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch')\n",
    "\n",
    "callbacks = [model_checkpoint, tb,terminate_on_nan]\n",
    "\n",
    "# initialize the model and optimizer\n",
    "print(\"[INFO] training network...\")\n",
    "# opt = SGD(lr=INIT_LR, momentum=0.5, decay=INIT_LR / EPOCHS)\n",
    "\n",
    "opt = Adam(lr=INIT_LR, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "# train the network\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),\n",
    "    validation_data=(testX, testY), steps_per_epoch=len(trainX) // BS,\n",
    "    epochs=EPOCHS,callbacks=callbacks)\n",
    "\n",
    "\n",
    "\n",
    "# Save the model locally for use later\n",
    "model_path = os.path.join(output_dir, 'path_to_my_VGG_model.h5')\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate the network\n",
    "logger.debug('Making predictions and evaluating the trained model.')\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),predictions.argmax(axis=1), target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "N = np.arange(0, EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(N, H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir,'smallvggnet_plot.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
