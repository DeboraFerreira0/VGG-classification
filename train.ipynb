{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2020-02-04 00:28:39.380 | DEBUG    | __main__:<module>:26 - All modules imported\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from vgg import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import copy\n",
    "from loguru import logger\n",
    "\n",
    "logger.debug('All modules imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-04 00:28:39.392 | DEBUG    | __main__:<module>:6 - [INFO] loading images...\n",
      "2020-02-04 00:29:04.358 | DEBUG    | __main__:<module>:33 - [INFO] data loaded complete...\n"
     ]
    }
   ],
   "source": [
    "cur_dir = os.getcwd()\n",
    "# the data is located in this data_dir\n",
    "data_dir = os.path.join(cur_dir, 'Dataset')\n",
    "\n",
    "# initialize the data and labels\n",
    "logger.debug(\"[INFO] loading images...\")\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# grab the image paths and shuffle them\n",
    "imagePaths = sorted(list(paths.list_images(os.path.join(data_dir, 'Data') )))\n",
    "\n",
    "# for reproducible results, use a constant seed for shuffling\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "    \n",
    "    # load the image\n",
    "    image = cv2.imread(imagePath)\n",
    "    \n",
    "    # resize it\n",
    "    image = cv2.resize(image, (32, 32))\n",
    "    \n",
    "    # append to the data list\n",
    "    data.append(image)\n",
    "\n",
    "    # extract the class label from the image path and update the labels list\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(label)\n",
    "\n",
    "logger.debug('[INFO] data loaded complete...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loaded = copy.deepcopy(data)\n",
    "labels_loaded = copy.deepcopy(labels)\n",
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data_loaded, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels_loaded)\n",
    "\n",
    "# Binarize labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "\n",
    "\n",
    "# Randomly split the data into test and train sets (25% test and 75% train)\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "    horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "# initialize our VGG-like Convolutional Neural Network\n",
    "model = SmallVGGNet.build(width=32, height=32, depth=3,\n",
    "    classes=len(lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/30\n",
      "118/118 [==============================] - 46s 389ms/step - loss: 1.9521 - acc: 0.4118 - val_loss: 1.2778 - val_acc: 0.6284\n",
      "Epoch 2/30\n",
      "118/118 [==============================] - 30s 257ms/step - loss: 1.2500 - acc: 0.6030 - val_loss: 0.6936 - val_acc: 0.7655\n",
      "Epoch 3/30\n",
      "118/118 [==============================] - 30s 250ms/step - loss: 0.9344 - acc: 0.6946 - val_loss: 0.5504 - val_acc: 0.8090\n",
      "Epoch 4/30\n",
      "118/118 [==============================] - 29s 249ms/step - loss: 0.8757 - acc: 0.7171 - val_loss: 0.8059 - val_acc: 0.7559\n",
      "Epoch 5/30\n",
      "118/118 [==============================] - 32s 271ms/step - loss: 0.6887 - acc: 0.7648 - val_loss: 3.3573 - val_acc: 0.3106\n",
      "Epoch 6/30\n",
      "118/118 [==============================] - 29s 246ms/step - loss: 0.7038 - acc: 0.7685 - val_loss: 0.4819 - val_acc: 0.8368\n",
      "Epoch 7/30\n",
      "118/118 [==============================] - 28s 240ms/step - loss: 0.6227 - acc: 0.7906 - val_loss: 0.6257 - val_acc: 0.7686\n",
      "Epoch 8/30\n",
      "118/118 [==============================] - 29s 244ms/step - loss: 0.5954 - acc: 0.8031 - val_loss: 0.4293 - val_acc: 0.8637\n",
      "Epoch 9/30\n",
      "118/118 [==============================] - 28s 240ms/step - loss: 0.5447 - acc: 0.8216 - val_loss: 0.4132 - val_acc: 0.8637\n",
      "Epoch 10/30\n",
      "118/118 [==============================] - 29s 242ms/step - loss: 0.5351 - acc: 0.8288 - val_loss: 0.5074 - val_acc: 0.8352\n",
      "Epoch 11/30\n",
      "118/118 [==============================] - 33s 276ms/step - loss: 0.5153 - acc: 0.8211 - val_loss: 0.3454 - val_acc: 0.8899\n",
      "Epoch 12/30\n",
      "118/118 [==============================] - 32s 275ms/step - loss: 0.5187 - acc: 0.8372 - val_loss: 0.3410 - val_acc: 0.8922\n",
      "Epoch 13/30\n",
      "118/118 [==============================] - 28s 241ms/step - loss: 0.4800 - acc: 0.8384 - val_loss: 0.7896 - val_acc: 0.7607\n",
      "Epoch 14/30\n",
      "118/118 [==============================] - 29s 242ms/step - loss: 0.4697 - acc: 0.8388 - val_loss: 0.3885 - val_acc: 0.8732\n",
      "Epoch 15/30\n",
      "118/118 [==============================] - 29s 248ms/step - loss: 0.4445 - acc: 0.8460 - val_loss: 0.2905 - val_acc: 0.9065\n",
      "Epoch 16/30\n",
      "118/118 [==============================] - 31s 259ms/step - loss: 0.4347 - acc: 0.8518 - val_loss: 0.4619 - val_acc: 0.8502\n",
      "Epoch 17/30\n",
      "118/118 [==============================] - 29s 243ms/step - loss: 0.4199 - acc: 0.8560 - val_loss: 0.2840 - val_acc: 0.9097\n",
      "Epoch 18/30\n",
      "118/118 [==============================] - 29s 242ms/step - loss: 0.4070 - acc: 0.8723 - val_loss: 0.2537 - val_acc: 0.9152\n",
      "Epoch 19/30\n",
      "118/118 [==============================] - 28s 240ms/step - loss: 0.4150 - acc: 0.8674 - val_loss: 0.3259 - val_acc: 0.8922\n",
      "Epoch 20/30\n",
      "118/118 [==============================] - 28s 240ms/step - loss: 0.4081 - acc: 0.8663 - val_loss: 0.3801 - val_acc: 0.8803\n",
      "Epoch 21/30\n",
      "118/118 [==============================] - 28s 239ms/step - loss: 0.3684 - acc: 0.8771 - val_loss: 0.2843 - val_acc: 0.9081\n",
      "Epoch 22/30\n",
      "118/118 [==============================] - 29s 242ms/step - loss: 0.4060 - acc: 0.8641 - val_loss: 0.2735 - val_acc: 0.9081\n",
      "Epoch 23/30\n",
      "118/118 [==============================] - 28s 240ms/step - loss: 0.3708 - acc: 0.8729 - val_loss: 0.2780 - val_acc: 0.9120\n",
      "Epoch 24/30\n",
      "118/118 [==============================] - 29s 242ms/step - loss: 0.3959 - acc: 0.8621 - val_loss: 0.2673 - val_acc: 0.9184\n",
      "Epoch 25/30\n",
      "118/118 [==============================] - 30s 256ms/step - loss: 0.3651 - acc: 0.8807 - val_loss: 0.2586 - val_acc: 0.9208\n",
      "Epoch 26/30\n",
      "118/118 [==============================] - 30s 251ms/step - loss: 0.3600 - acc: 0.8804 - val_loss: 0.2917 - val_acc: 0.9128\n",
      "Epoch 27/30\n",
      "118/118 [==============================] - 31s 266ms/step - loss: 0.3875 - acc: 0.8736 - val_loss: 0.3457 - val_acc: 0.8946\n",
      "Epoch 28/30\n",
      "118/118 [==============================] - 30s 253ms/step - loss: 0.3210 - acc: 0.8901 - val_loss: 0.2469 - val_acc: 0.9152\n",
      "Epoch 29/30\n",
      "118/118 [==============================] - 29s 246ms/step - loss: 0.3414 - acc: 0.8889 - val_loss: 0.2538 - val_acc: 0.9192\n",
      "Epoch 30/30\n",
      "118/118 [==============================] - 29s 249ms/step - loss: 0.3446 - acc: 0.8841 - val_loss: 0.2504 - val_acc: 0.9208\n"
     ]
    }
   ],
   "source": [
    "# initialize our initial learning rate, # of epochs to train for,\n",
    "# and batch size\n",
    "INIT_LR = 0.01\n",
    "EPOCHS = 30\n",
    "BS = 32\n",
    "\n",
    "# initialize the model and optimizer (you'll want to use\n",
    "# binary_crossentropy for 2-class classification)\n",
    "print(\"[INFO] training network...\")\n",
    "opt = SGD(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "# train the network\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),\n",
    "    validation_data=(testX, testY), steps_per_epoch=len(trainX) // BS,\n",
    "    epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "['black_dress' 'black_pants' 'black_shoes' 'blue_dress' 'blue_pants'\n",
      " 'blue_shirt' 'green_shoes' 'red_dress' 'red_shoes' 'white_dress']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " black_dress       0.93      0.90      0.91        99\n",
      " black_pants       0.93      0.95      0.94       143\n",
      " black_shoes       0.88      0.85      0.86       130\n",
      "  blue_dress       0.90      0.89      0.90       122\n",
      "  blue_pants       0.87      0.91      0.89       135\n",
      "  blue_shirt       0.95      0.89      0.92       122\n",
      " green_shoes       0.89      0.95      0.92       108\n",
      "   red_dress       0.97      0.96      0.97       134\n",
      "   red_shoes       0.94      0.93      0.93       149\n",
      " white_dress       0.95      0.97      0.96       120\n",
      "\n",
      "    accuracy                           0.92      1262\n",
      "   macro avg       0.92      0.92      0.92      1262\n",
      "weighted avg       0.92      0.92      0.92      1262\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "print(lb.classes_)\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),predictions.argmax(axis=1), target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "N = np.arange(0, EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(N, H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy (SmallVGGNet)\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig('smallvggnet_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
